{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938eb00c-3f1a-4b40-9016-032d9fa8f9ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fast_transformers.attention import FullAttention,LinearAttention,CausalLinearAttention\n",
    "import torch\n",
    "from protein_dataset import Protein_Dataset,collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "from classifier import Protein_Classifier2,Protein_Classifier_LoRA\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from torchvision.ops.focal_loss import sigmoid_focal_loss\n",
    "import torch.nn.functional as F\n",
    "# from pynvml import *\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "N_BATCH =512\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "dataset=Protein_Dataset(split=\"train\")\n",
    "dataset_val=Protein_Dataset(split=\"val\")\n",
    "\n",
    "int2clss = dataset.int2clss\n",
    "\n",
    "train_dataloader=DataLoader(dataset,batch_size=N_BATCH,collate_fn=collate_fn,shuffle=True)\n",
    "val_dataloader=DataLoader(dataset,batch_size=N_BATCH,collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceacb9d7-a7b8-4660-bbe6-1f040ce73186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from fast_transformers.attention import LocalAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6deb2571-d069-4420-b1a1-65d49bb8746f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from fast_transformers.feature_maps import Favor,SmoothedRandomFourierFeatures\n",
    "# FavorAttention = partial(LinearAttention,query_dimensions=256//8,feature_map=partial(Favor,n_dims=64))\n",
    "FavorAttention = partial(LinearAttention,query_dimensions=256//8,feature_map=Favor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a9ff2b1-376e-4b87-9544-c0c5b1644fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers = [FullAttention,FullAttention,FullAttention,FavorAttention,FavorAttention,FavorAttention]\n",
    "layers = [LinearAttention for _ in range(6)]\n",
    "# model = Protein_Classifier_LoRA(layer = LinearAttention,dim=256,n_layers=6,n_heads=8,dim_feedfwd=512,causal=False,r=4)\n",
    "model = Protein_Classifier2(layers=layers,dim=256,n_layers=6,n_heads=8,dim_feedfwd=512,causal=False)\n",
    "D = torch.load(\"./weights/linear_model.pth\")[\"params\"]\n",
    "model.load_state_dict(D,strict=False)\n",
    "model.cuda()\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a310b50f-d372-4e8f-b4ab-bbeec5988b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LoRA_Params = [param for n,param in model.named_parameters() if \"LoRA_adapter\" in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1adeb6e-b7d0-4dc6-b219-e6fe9518e4c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0, 3177761)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "params = sum([np.prod(p.size()) for p in model.parameters()])\n",
    "l_params = sum([np.prod(p.size()) for p in LoRA_Params])\n",
    "(l_params/params)*100,l_params,params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8b878cb-dbe7-4209-b9d7-163dc214dd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 484/484 [01:42<00:00,  4.70it/s]\n"
     ]
    }
   ],
   "source": [
    "val_loss = 0\n",
    "val_acc = 0\n",
    "val_samples = 0\n",
    "ys = []\n",
    "preds = []\n",
    "model.eval()\n",
    "for src, tgt in tqdm(val_dataloader):\n",
    "    with torch.no_grad():\n",
    "        src=src.cuda()\n",
    "        tgt=tgt.cuda()\n",
    "        y_oh = F.one_hot(tgt,33)\n",
    "        logits = model(src)\n",
    "        loss = sigmoid_focal_loss(logits,y_oh.float()).mean()\n",
    "\n",
    "        equals = (logits.sigmoid().argmax(1)==tgt).reshape(-1,1).detach().cpu()\n",
    "        val_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
    "        val_loss += src.shape[0] * loss.item()\n",
    "        val_samples += src.shape[0]\n",
    "\n",
    "        ys.append(y_oh.cpu().numpy())\n",
    "        preds.append(logits.softmax(dim=1).cpu().numpy())\n",
    "\n",
    "ys = np.vstack(ys)\n",
    "preds = np.vstack(preds)\n",
    "test_dict = {}\n",
    "\n",
    "aps = 0\n",
    "for i in range(ys.shape[1]):\n",
    "    ap = average_precision_score(ys[:,i:i+1],preds[:,i:i+1])\n",
    "    aps += ap\n",
    "    test_dict[int2clss[i]] = ap\n",
    "    \n",
    "mAP = aps/ys.shape[1]\n",
    "\n",
    "\n",
    "val_loss = (val_loss/val_samples)\n",
    "val_acc = (val_acc/val_samples)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ffc442b-8ddc-409f-9625-b3ceaed0655c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002836259463698521, 0.9066208846697636, 0.9040897279777705)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss,val_acc,mAP\n",
    "\n",
    "#Full Attn Weights\n",
    "# Full : (0.002505175754773276, 0.9286366390628156, 0.9366763471453218)\n",
    "# Linear: (0.018903504853127244, 0.262754998990103, 0.13435013169830362)\n",
    "\n",
    "\n",
    "# From Back 1: (0.004965315841136858, 0.7645445364572814, 0.8383416077302199)\n",
    "# From Back 2: (0.009145309982745726, 0.547247020803878, 0.6100587362213996)\n",
    "# From Back 3:(0.011577269005403148, 0.44243991112906483, 0.3866045301048777)\n",
    "\n",
    "#From Front 1: (0.009175984509262177, 0.5768814380933145, 0.5572050056187545)\n",
    "#From Front 2: (0.016363995414181348, 0.3479256715814987, 0.3177880819238023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "886f00b0-0e13-44f0-b34e-9cd6c6fe7102",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amazon_Classifier(\n",
       "  (enc): Encoder(\n",
       "    (enc): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (attention): AttentionLayer(\n",
       "            (inner_attention): LinearAttention(\n",
       "              (feature_map): ActivationFunctionFeatureMap()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key_projection): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value_projection): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_projection): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (emb): Embedding(50002, 256)\n",
       "  (class_head): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a7a114c-1780-491e-9a56-46dc1013b663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.503004312515259"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "for _ in range(1000):\n",
    "    with torch.no_grad():\n",
    "        logits = model(src)\n",
    "t2 = time.time()\n",
    "\n",
    "t2-t1\n",
    "\n",
    "#Linear : 6.503004312515259\n",
    "#Full:7.042819261550903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08d0323f-fd3c-49c2-997e-b2fbbb8e131a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.083010086276085"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7.042819261550903/6.503004312515259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5433cc12-a2a9-452b-9d81-a9d1aed76d13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 191])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9de1ebc-b209-4c17-9968-a089dfa09e58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 36,  26,  16,  ...,   1,   1,   1],\n",
       "        [694,  12,  11,  ...,   1,   1,   1],\n",
       "        [  5, 118, 156,  ...,   1,   1,   1],\n",
       "        ...,\n",
       "        [  5, 110,  12,  ...,   1,   1,   1],\n",
       "        [ 36,  11,   8,  ...,   1,   1,   1],\n",
       "        [ 36, 189,  59,  ...,   1,   1,   1]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d25f4-b1dc-4a47-86b5-c947088a4e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
